{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch.nn as nn \n",
    "import torch.nn.functional as F\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "from utils.dataset import MIND_Train\n",
    "from utils.manager import Manager\n",
    "from utils.util import load_pickle, save_pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2022-02-09 10:20:50,883] INFO (Manager) Hyper Parameters are:\n",
      "{'scale': 'demo', 'batch_size': 2, 'batch_size_encode': 2, 'dropout_p': 0.1, 'seed': 3407, 'dataloaders': ['train', 'dev', 'news', 'history'], 'his_size': 50, 'impr_size': 20, 'negative_num': 4, 'title_length': 32, 'abs_length': 64, 'plm': 'bert', 'enable_fields': ['title', 'abs'], 'enable_gate': 'weight', 'verbose': None, 'sequence_length': 96}\n",
      "\n",
      "[2022-02-09 10:20:50,888] INFO (MIND_Train) Loading Cache at MINDdemo_train\n",
      "[2022-02-09 10:20:52,482] INFO (MIND_Dev) Loading Cache at MINDdemo_dev\n",
      "[2022-02-09 10:20:53,630] INFO (MIND_News) Loading Cache at MINDdemo_dev\n"
     ]
    }
   ],
   "source": [
    "class config:\n",
    "    epochs = 10\n",
    "    scale = \"demo\"\n",
    "    mode = \"train\"\n",
    "    device = 0\n",
    "    batch_size = 2\n",
    "    batch_size_encode = 2\n",
    "    dropout_p = 0.1\n",
    "    seed = 3407\n",
    "    world_size = 1\n",
    "\n",
    "    data_root = \"../../../Data\"\n",
    "    cache_root = \"data/cache\"\n",
    "    dataloaders = [\"train\", \"dev\", \"news\", \"history\"]\n",
    "\n",
    "    his_size = 50\n",
    "    impr_size = 20\n",
    "    negative_num = 4\n",
    "\n",
    "    max_title_length = 64\n",
    "    max_abs_length = 256\n",
    "    title_length = 32\n",
    "    abs_length = 64\n",
    "\n",
    "    plm = \"bert\"\n",
    "\n",
    "    enable_fields = [\"title\", \"abs\"]\n",
    "    enable_gate = \"weight\"\n",
    "\n",
    "    rank = 0\n",
    "    verbose = None\n",
    "    distributed = False\n",
    "    debug = False\n",
    "\n",
    "manager = Manager(config, notebook=True)\n",
    "loaders = manager.prepare()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "loader_train = loaders[\"train\"]\n",
    "loader_dev = loaders[\"dev\"]\n",
    "loader_news = loaders[\"news\"]\n",
    "\n",
    "dataset_train = loader_train.dataset\n",
    "dataset_dev = loader_dev.dataset\n",
    "dataset_news = loader_news.dataset\n",
    "\n",
    "X1 = iter(loader_train)\n",
    "X2 = iter(loader_dev)\n",
    "X3 = iter(loader_news)\n",
    "x = next(X1)\n",
    "x2 = next(X2)\n",
    "x3 = next(X3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'impr_index': tensor([0, 0]),\n",
       " 'user_index': tensor([506263, 506263]),\n",
       " 'cdd_idx': tensor([[36180, 41328, 41034, 39776, 34983, 37322, 37327, 36307, 36185, 36349,\n",
       "          38581, 39227, 37368, 33705, 39921, 39640, 36275, 38848,  7014, 37943],\n",
       "         [39086, 24209,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0]]),\n",
       " 'his_idx': tensor([[ 7499, 34171, 15796, 32731, 32139, 18228,  1736, 30270, 35479, 30833,\n",
       "          12951, 26650, 30302,  1692, 36210,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
       "         [ 7499, 34171, 15796, 32731, 32139, 18228,  1736, 30270, 35479, 30833,\n",
       "          12951, 26650, 30302,  1692, 36210,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0]]),\n",
       " 'cdd_mask': tensor([[ True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "           True,  True,  True,  True,  True,  True,  True,  True,  True,  True],\n",
       "         [ True,  True, False, False, False, False, False, False, False, False,\n",
       "          False, False, False, False, False, False, False, False, False, False]]),\n",
       " 'his_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0],\n",
       "         [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0]]),\n",
       " 'cdd_token_id': tensor([[[  101, 13240, 12134,  ...,     0,     0,     0],\n",
       "          [  101,  1045,  1005,  ...,     0,     0,     0],\n",
       "          [  101,  5448,  1024,  ...,     0,     0,     0],\n",
       "          ...,\n",
       "          [  101,  4202,  9170,  ...,     0,     0,     0],\n",
       "          [  101,  1996,  2087,  ...,     0,     0,     0],\n",
       "          [  101, 19337, 11319,  ...,     0,     0,     0]],\n",
       " \n",
       "         [[  101,  2410,  4436,  ...,     0,     0,     0],\n",
       "          [  101,  5764,  4658,  ...,     0,     0,     0],\n",
       "          [    0,     0,     0,  ...,     0,     0,     0],\n",
       "          ...,\n",
       "          [    0,     0,     0,  ...,     0,     0,     0],\n",
       "          [    0,     0,     0,  ...,     0,     0,     0],\n",
       "          [    0,     0,     0,  ...,     0,     0,     0]]]),\n",
       " 'his_token_id': tensor([[[  101,  1005,  5217,  ...,     0,     0,     0],\n",
       "          [  101,  2524,  2600,  ...,     0,     0,     0],\n",
       "          [  101, 27357, 21301,  ...,     0,     0,     0],\n",
       "          ...,\n",
       "          [    0,     0,     0,  ...,     0,     0,     0],\n",
       "          [    0,     0,     0,  ...,     0,     0,     0],\n",
       "          [    0,     0,     0,  ...,     0,     0,     0]],\n",
       " \n",
       "         [[  101,  1005,  5217,  ...,     0,     0,     0],\n",
       "          [  101,  2524,  2600,  ...,     0,     0,     0],\n",
       "          [  101, 27357, 21301,  ...,     0,     0,     0],\n",
       "          ...,\n",
       "          [    0,     0,     0,  ...,     0,     0,     0],\n",
       "          [    0,     0,     0,  ...,     0,     0,     0],\n",
       "          [    0,     0,     0,  ...,     0,     0,     0]]]),\n",
       " 'cdd_attn_mask': tensor([[[1, 1, 1,  ..., 0, 0, 0],\n",
       "          [1, 1, 1,  ..., 0, 0, 0],\n",
       "          [1, 1, 1,  ..., 0, 0, 0],\n",
       "          ...,\n",
       "          [1, 1, 1,  ..., 0, 0, 0],\n",
       "          [1, 1, 1,  ..., 0, 0, 0],\n",
       "          [1, 1, 1,  ..., 0, 0, 0]],\n",
       " \n",
       "         [[1, 1, 1,  ..., 0, 0, 0],\n",
       "          [1, 1, 1,  ..., 0, 0, 0],\n",
       "          [0, 0, 0,  ..., 0, 0, 0],\n",
       "          ...,\n",
       "          [0, 0, 0,  ..., 0, 0, 0],\n",
       "          [0, 0, 0,  ..., 0, 0, 0],\n",
       "          [0, 0, 0,  ..., 0, 0, 0]]]),\n",
       " 'his_attn_mask': tensor([[[1, 1, 1,  ..., 0, 0, 0],\n",
       "          [1, 1, 1,  ..., 0, 0, 0],\n",
       "          [1, 1, 1,  ..., 0, 0, 0],\n",
       "          ...,\n",
       "          [0, 0, 0,  ..., 0, 0, 0],\n",
       "          [0, 0, 0,  ..., 0, 0, 0],\n",
       "          [0, 0, 0,  ..., 0, 0, 0]],\n",
       " \n",
       "         [[1, 1, 1,  ..., 0, 0, 0],\n",
       "          [1, 1, 1,  ..., 0, 0, 0],\n",
       "          [1, 1, 1,  ..., 0, 0, 0],\n",
       "          ...,\n",
       "          [0, 0, 0,  ..., 0, 0, 0],\n",
       "          [0, 0, 0,  ..., 0, 0, 0],\n",
       "          [0, 0, 0,  ..., 0, 0, 0]]]),\n",
       " 'label': [tensor([0, 0]),\n",
       "  tensor([0, 0]),\n",
       "  tensor([ 1, -1]),\n",
       "  tensor([ 0, -1]),\n",
       "  tensor([ 0, -1]),\n",
       "  tensor([ 0, -1]),\n",
       "  tensor([ 0, -1]),\n",
       "  tensor([ 0, -1]),\n",
       "  tensor([ 0, -1]),\n",
       "  tensor([ 0, -1]),\n",
       "  tensor([ 0, -1]),\n",
       "  tensor([ 0, -1]),\n",
       "  tensor([ 0, -1]),\n",
       "  tensor([ 0, -1]),\n",
       "  tensor([ 0, -1]),\n",
       "  tensor([ 0, -1]),\n",
       "  tensor([ 0, -1]),\n",
       "  tensor([ 0, -1]),\n",
       "  tensor([ 0, -1]),\n",
       "  tensor([ 0, -1])],\n",
       " 'cdd_gate_mask': tensor([[[0, 1, 1,  ..., 0, 0, 0],\n",
       "          [0, 1, 1,  ..., 0, 0, 0],\n",
       "          [0, 1, 1,  ..., 0, 0, 0],\n",
       "          ...,\n",
       "          [0, 1, 1,  ..., 0, 0, 0],\n",
       "          [0, 1, 1,  ..., 0, 0, 0],\n",
       "          [0, 1, 1,  ..., 0, 0, 0]],\n",
       " \n",
       "         [[0, 1, 1,  ..., 0, 0, 0],\n",
       "          [0, 1, 1,  ..., 0, 0, 0],\n",
       "          [0, 0, 0,  ..., 0, 0, 0],\n",
       "          ...,\n",
       "          [0, 0, 0,  ..., 0, 0, 0],\n",
       "          [0, 0, 0,  ..., 0, 0, 0],\n",
       "          [0, 0, 0,  ..., 0, 0, 0]]]),\n",
       " 'his_gate_mask': tensor([[[0, 1, 1,  ..., 0, 0, 0],\n",
       "          [0, 1, 1,  ..., 0, 0, 0],\n",
       "          [0, 1, 1,  ..., 0, 0, 0],\n",
       "          ...,\n",
       "          [0, 0, 0,  ..., 0, 0, 0],\n",
       "          [0, 0, 0,  ..., 0, 0, 0],\n",
       "          [0, 0, 0,  ..., 0, 0, 0]],\n",
       " \n",
       "         [[0, 1, 1,  ..., 0, 0, 0],\n",
       "          [0, 1, 1,  ..., 0, 0, 0],\n",
       "          [0, 1, 1,  ..., 0, 0, 0],\n",
       "          ...,\n",
       "          [0, 0, 0,  ..., 0, 0, 0],\n",
       "          [0, 0, 0,  ..., 0, 0, 0],\n",
       "          [0, 0, 0,  ..., 0, 0, 0]]])}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = AutoTokenizer.from_pretrained(manager.plm_dir)\n",
    "# m = AutoModel.from_pretrained(manager.bert_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['U63949', 'U28675'] [1633, 526]\n",
      "['N33159', 'N29128', 'N55689', 'N59981', 'N47229']\n",
      "[\"sheriff's deputy charged with murder after man shot, killed a sheriff's deputy is in jail, charged with murder after a deadly shooting in athens, authorities said.\", \"flight attendants have a secret language you didn't know about here are some phrases only flight attendant use and what they actually mean.\", 'charles rogers, former michigan state football, detroit lions star, dead at 38 charles rogers, the former michigan state football star whom the detroit lions selected with the second overall pick in 2003 nfl draft, has died.', \"tamron hall talks leaving the today show, jokes about megyn kelly's reported multimillion payout tamron hall talks losing the today show\", 'these are the best harley - davidson motorcycles you can get for the cheap these are the best harleys to buy right now.']\n",
      "['N1150', 'N29177', 'N29898', 'N46392', 'N54772']\n",
      "['a texas mom is going to prison after putting her son through unnecessary medical procedures a dallas mother made her son go through unnecessary medical procedures throughout the first years of his life, court documents say.', \"miguel cervantes'wife reveals daughter, 3,'died in my arms'after entering hospice care miguel cervantes'wife reveals daughter'died in my arms'after hospice care\", 'basket - shaped building to become a luxury hotel in newark, ohio a seven - story building in the shape of a picnic basket - - complete with handles - - is set to be converted into a luxury hotel. the former longaberger co. headquarters is in newark, ohio.', 'body of missing alabama girl found ; 2 being charged investigators searching through garbage found the body of a 3 - year - old girl who was missing more than a week, and authorities are charging two people with murder, police said tuesday.', 'woman doused with gasoline, set afire at florida taco bell. police arrest suspect police are searching for a suspect who entered a tallahassee taco bell, doused a woman with gasoline, set her on fire, then fled.']\n"
     ]
    }
   ],
   "source": [
    "# check train loader result\n",
    "nid2index = load_pickle(\"/data/v-pezhang/Code/GateFormer/src/data/cache/MIND/MINDdemo_train/news/nid2index.pkl\")\n",
    "uid2index = load_pickle(\"/data/v-pezhang/Code/GateFormer/src/data/cache/MIND/uid2index.pkl\")\n",
    "nindex2id = {v:k for k,v in nid2index.items()}\n",
    "uindex2id = {v:k for k,v in uid2index.items()}\n",
    "\n",
    "# check behaviors.tsv\n",
    "print([uindex2id[i] for i in x[\"user_index\"].tolist()], (x[\"impr_index\"] + 1).tolist())\n",
    "# check news.tsv\n",
    "print([nindex2id[i] for i in x[\"cdd_idx\"][0][:5].tolist()])\n",
    "print(t.batch_decode(x[\"cdd_token_id\"][0][:5], skip_special_tokens=True))\n",
    "\n",
    "print([nindex2id[i] for i in x[\"his_idx\"][0][:5].tolist()])\n",
    "print(t.batch_decode(x[\"his_token_id\"][0][:5], skip_special_tokens=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['U80234', 'U80234'] [1, 1]\n",
      "['N28682', 'N48740', 'N31958', 'N34130', 'N6916']\n",
      "[\"browns apologize to mason rudolph, call myles garrett's actions'unacceptable'players often defend their teammates when commenting on an incident like the one we saw thursday, but the immediate reaction from mayfield and others proves just how far garrett crossed the line.\", \"i've been writing about tiny homes for a year and finally spent 2 nights in a 300 - foot home to see what it's all about i stayed in a tiny house for three days to see what the fuss was all about, and i was surprised by what i saw.\", 'opinion : colin kaepernick is about to get what he deserves : a chance the end may be near for the 3 - year - old saga of colin kaepernick as the quarterback is scheduled to work out for teams on saturday.', \"the kardashians face backlash over'insensitive'family food fight in kuwtk clip kardashian's face backlash over family food fight\", \"then and now : what all your favorite'90s stars are doing today these heartthrobs and fan favorites made the 1990s one of the best decades of the century. here's what they're up to now.\"]\n",
      "['N55189', 'N46039', 'N51741', 'N53234', 'N11276']\n",
      "['\\' wheel of fortune\\'guest delivers hilarious, off the rails introduction we\\'d like to solve the puzzle, pat : blair davis\\'loveless marriage? on monday, \" wheel of fortune \" welcomed as a new contestant trucking business owner blair davis, who offered a biting introduction for himself. when host pat sajak asked the man from cardiff, california, about his family', 'hard rock hotel new orleans collapse : former site engineer weighs in structural engineer walter zehner worked on the project before it became a planned hard rock hotel. a look at what he thinks could have happened :', 'felicity huffman begins prison sentence for college admissions scam the actress will spend 14 days inside a federal lockup outside of san francisco.', 'outer banks storms unearth old shipwreck from\\'graveyard of the atlantic\\'a recent storm on the outer banks unearthed an old shipwreck buried on the beach in hatteras island. a local bar shared photos of the old wooden ship in its final resting place in the area known as \" the graveyard of the atlantic. \" \" a wreck across the street from the wreck! a', \"tiffany's is selling a holiday advent calendar for $ 112, 000 each display contains 24 items including earrings, bracelets and even a sterling silver harmonica.\"]\n"
     ]
    }
   ],
   "source": [
    "# check dev loader result\n",
    "nid2index = load_pickle(\"/data/v-pezhang/Code/GateFormer/src/data/cache/MIND/MINDdemo_dev/news/nid2index.pkl\")\n",
    "uid2index = load_pickle(\"/data/v-pezhang/Code/GateFormer/src/data/cache/MIND/uid2index.pkl\")\n",
    "nindex2id = {v:k for k,v in nid2index.items()}\n",
    "uindex2id = {v:k for k,v in uid2index.items()}\n",
    "\n",
    "# check behaviors.tsv\n",
    "print([uindex2id[i] for i in x2[\"user_index\"].tolist()], (x2[\"impr_index\"] + 1).tolist())\n",
    "# check news.tsv\n",
    "print([nindex2id[i] for i in x2[\"cdd_idx\"][0][:5].tolist()])\n",
    "print(t.batch_decode(x2[\"cdd_token_id\"][0][:5], skip_special_tokens=True))\n",
    "\n",
    "print([nindex2id[i] for i in x2[\"his_idx\"][0][:5].tolist()])\n",
    "print(t.batch_decode(x2[\"his_token_id\"][0][:5], skip_special_tokens=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "a256a4def3bbb1bd6a1d46703c4995443a919758d62b261face579c969ba8076"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit ('nn': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
